"""
Mogul Design Agency - AI Agent API
Production-Ready: Phase 1 + Phase 2 Complete

Phase 1:
- Structured JSON Logging
- Request Tracing (Correlation IDs)
- Rate Limiting
- Authentication
- Security Headers

Phase 2:
- Retry Logic with Exponential Backoff
- Context Window Management
- AI Safety Guardrails
- Input Sanitization
"""

import os
import io
import json
import traceback
from typing import Dict, Any, List, Optional
from datetime import datetime
from pathlib import Path
from contextlib import asynccontextmanager

from fastapi import FastAPI, Request, UploadFile, File, HTTPException, status, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import (
    JSONResponse,
    HTMLResponse,
    RedirectResponse,
    StreamingResponse,
    Response,
)
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, field_validator
from dotenv import load_dotenv

# =====================================================
# CONFIGURATION
# =====================================================

BASE_DIR = Path(__file__).resolve().parent
ENV_PATH = BASE_DIR / ".env"
load_dotenv(dotenv_path=ENV_PATH)

# Required
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Optional with defaults
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
DEFAULT_TZ = os.getenv("DEFAULT_TZ", "America/New_York")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID", "yM93hbw8Qtvdma2wCnJG")
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
DEBUG = os.getenv("DEBUG", "false").lower() == "true"

# Safety settings
ENABLE_GUARDRAILS = os.getenv("ENABLE_GUARDRAILS", "true").lower() == "true"
MAX_CONTEXT_TOKENS = int(os.getenv("MAX_CONTEXT_TOKENS", "50000"))

# =====================================================
# LOGGING SETUP
# =====================================================

from logging_config import setup_logging, get_logger, request_id_var

logger = setup_logging(
    name="mogul",
    level=os.getenv("LOG_LEVEL", "INFO"),
    json_format=(ENVIRONMENT == "production")
)

def _mask(key: Optional[str]) -> str:
    """Safely mask API keys for logging."""
    if not key:
        return "None"
    if len(key) <= 8:
        return key[0] + "***" + key[-1]
    return key[:4] + "..." + key[-4:]

# Startup logging
logger.info("=" * 50)
logger.info("MOGUL AI AGENT - STARTUP")
logger.info("=" * 50)
logger.info(f"Environment: {ENVIRONMENT}")
logger.info(f"BASE_DIR: {BASE_DIR}")
logger.info(f"OPENAI_API_KEY: {'‚úÖ' if OPENAI_API_KEY else '‚ùå MISSING'}")
logger.info(f"MODEL: {MODEL}")
logger.info(f"ELEVENLABS: {'‚úÖ' if ELEVENLABS_API_KEY else '‚ö†Ô∏è disabled'}")
logger.info(f"GUARDRAILS: {'‚úÖ enabled' if ENABLE_GUARDRAILS else '‚ö†Ô∏è disabled'}")
logger.info(f"MAX_CONTEXT_TOKENS: {MAX_CONTEXT_TOKENS}")
logger.info("=" * 50)

# =====================================================
# ERROR HANDLING
# =====================================================

class APIError(Exception):
    """Custom API error with status code and structured response."""
    def __init__(
        self, 
        status_code: int, 
        error_code: str, 
        message: str, 
        detail: str = None
    ):
        self.status_code = status_code
        self.error_code = error_code
        self.message = message
        self.detail = detail
        super().__init__(message)

def error_response(
    status_code: int, 
    error_code: str, 
    message: str, 
    detail: str = None,
    request_id: str = None
) -> JSONResponse:
    """Create a standardized error response."""
    content = {
        "error": error_code,
        "message": message,
    }
    if detail and DEBUG:
        content["detail"] = detail
    if request_id:
        content["request_id"] = request_id
    return JSONResponse(status_code=status_code, content=content)

# =====================================================
# FIREBASE / FIRESTORE
# =====================================================

import firebase_admin
from firebase_admin import credentials, firestore

db = None

def init_firestore():
    global db
    if firebase_admin._apps:
        db = firestore.client()
        return
    
    try:
        creds_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
        if creds_path and Path(creds_path).exists():
            cred = credentials.Certificate(creds_path)
            logger.info(f"Firebase: using credentials from {creds_path}")
        else:
            cred = credentials.ApplicationDefault()
            logger.info("Firebase: using Application Default credentials")
        
        firebase_admin.initialize_app(cred)
        db = firestore.client()
        logger.info("‚úÖ Firestore initialized")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Firestore disabled: {e}")
        db = None

init_firestore()

def save_chat_to_firestore(
    user_messages: List[Dict[str, Any]], 
    assistant_message: Dict[str, Any],
    request_id: str = None
):
    """Save chat interaction to Firestore for analytics."""
    if not db:
        return
    
    try:
        doc = {
            "created_at": datetime.utcnow().isoformat() + "Z",
            "model": MODEL,
            "messages": user_messages,
            "assistant_reply": assistant_message,
            "request_id": request_id,
        }
        db.collection("chat_logs").add(doc)
        logger.debug("Chat logged to Firestore")
    except Exception as e:
        logger.warning(f"Failed to write chat log: {e}")

# =====================================================
# OPENAI CLIENT WITH RETRY
# =====================================================

from openai import OpenAI, OpenAIError, APIError as OpenAIAPIError, RateLimitError, APIConnectionError

if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY is missing!")
    raise RuntimeError("OPENAI_API_KEY is required. Check your .env file.")

oai = OpenAI(api_key=OPENAI_API_KEY)

# Import retry utilities
from retry import with_retry, RetryExhausted, CircuitBreaker

# Circuit breaker for OpenAI
openai_breaker = CircuitBreaker(
    failure_threshold=5,
    recovery_timeout=60.0,
    half_open_max_calls=2,
)

# =====================================================
# ELEVENLABS CLIENT
# =====================================================

_eleven_client = None

if ELEVENLABS_API_KEY:
    try:
        from elevenlabs.client import ElevenLabs
        _eleven_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
        logger.info("‚úÖ ElevenLabs client initialized")
    except ImportError:
        logger.warning("elevenlabs package not installed")
    except Exception as e:
        logger.warning(f"ElevenLabs init failed: {e}")

# Circuit breaker for ElevenLabs
elevenlabs_breaker = CircuitBreaker(
    failure_threshold=3,
    recovery_timeout=30.0,
)

# =====================================================
# GOOGLE CLOUD CLIENTS
# =====================================================

_speech_client = None
_tts_client = None

def get_speech_client():
    """Lazily initialize Google Speech client."""
    global _speech_client
    if _speech_client is None:
        from google.cloud import speech_v1p1beta1 as speech
        _speech_client = speech.SpeechClient()
        logger.info("‚úÖ Google Speech client initialized")
    return _speech_client

def get_tts_client():
    """Lazily initialize Google TTS client."""
    global _tts_client
    if _tts_client is None:
        from google.cloud import texttospeech
        _tts_client = texttospeech.TextToSpeechClient()
        logger.info("‚úÖ Google TTS client initialized")
    return _tts_client

# =====================================================
# LOCAL TOOLS
# =====================================================

from tools import get_booking_link, lookup_customer, add_note

TOOL_SCHEMA = [
    {
        "type": "function",
        "function": {
            "name": "get_booking_link",
            "description": "Return the public booking link for a 30-minute call with Jordan.",
            "parameters": {"type": "object", "properties": {}, "required": []},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "lookup_customer",
            "description": "Check Firestore for an existing customer record by email or phone.",
            "parameters": {
                "type": "object",
                "properties": {
                    "email": {"type": "string"},
                    "phone": {"type": "string"},
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "add_note",
            "description": "Attach a summary of this conversation to an existing Firestore customer record.",
            "parameters": {
                "type": "object",
                "properties": {
                    "conversation_id": {"type": "string"},
                    "customer_id": {"type": "string"},
                    "summary": {"type": "string"},
                },
                "required": ["conversation_id", "customer_id", "summary"],
            },
        },
    },
]

TOOL_IMPL = {
    "get_booking_link": get_booking_link,
    "lookup_customer": lookup_customer,
    "add_note": add_note,
}

# =====================================================
# SYSTEM PROMPT
# =====================================================

from prompts import get_system_prompt, SYSTEM_PROMPT

# =====================================================
# CONVERSATION & GUARDRAILS
# =====================================================

from conversation import (
    trim_conversation_history,
    count_messages_tokens,
    validate_messages,
)

from guardrails import (
    full_safety_check,
    validate_tool_call,
    sanitize_messages,
)

# =====================================================
# TOOL EXECUTION
# =====================================================

async def _run_one_tool(name: str, args: Dict[str, Any]) -> Dict[str, Any]:
    """Execute a single tool call safely."""
    # Validate tool call
    is_valid, error = validate_tool_call(name, args)
    if not is_valid:
        logger.warning(f"Invalid tool call: {error}")
        return {"error": "invalid_tool_call", "detail": error}
    
    fn = TOOL_IMPL.get(name)
    if fn is None:
        logger.warning(f"Unknown tool called: {name}")
        return {"error": "unknown_tool", "tool": name}
    
    try:
        if name == "lookup_customer":
            email, phone = args.get("email"), args.get("phone")
            if not email and not phone:
                return {"error": "provide_email_or_phone"}
            return await fn(email=email, phone=phone)
        
        return await fn(**args)
    except Exception as e:
        logger.error(f"Tool execution error ({name}): {e}")
        return {"error": "tool_execution_failed", "detail": str(e)}

def _assistant_tool_call_dict(msg_obj) -> dict:
    """Convert assistant message with tool calls to dict format."""
    calls = []
    for tc in (msg_obj.tool_calls or []):
        calls.append({
            "id": tc.id,
            "type": "function",
            "function": {
                "name": tc.function.name,
                "arguments": tc.function.arguments or "{}",
            },
        })
    return {"role": "assistant", "tool_calls": calls}

async def _apply_tool_calls(base_msgs: List[dict], msg_obj) -> List[dict]:
    """Execute all tool calls and build the response messages."""
    tool_msgs: List[dict] = []
    assistant_tool = _assistant_tool_call_dict(msg_obj)
    
    for tc in (msg_obj.tool_calls or []):
        try:
            args = json.loads(tc.function.arguments or "{}")
        except json.JSONDecodeError:
            args = {}
        
        result = await _run_one_tool(tc.function.name, args)
        
        tool_msgs.append({
            "role": "tool",
            "tool_call_id": tc.id,
            "content": json.dumps(result),
        })
    
    return base_msgs + [assistant_tool] + tool_msgs

# =====================================================
# OPENAI CALL WITH RETRY
# =====================================================

@with_retry(
    max_attempts=3,
    base_delay=1.0,
    backoff_factor=2.0,
    exceptions=(RateLimitError, APIConnectionError),
)
async def call_openai_with_retry(messages: List[dict], use_tools: bool = True):
    """Call OpenAI API with retry logic."""
    # Check circuit breaker
    if not openai_breaker.allow_request():
        raise APIError(
            status_code=503,
            error_code="service_unavailable",
            message="AI service temporarily unavailable. Please try again in a moment."
        )
    
    try:
        kwargs = {
            "model": MODEL,
            "messages": messages,
            "stream": False,
        }
        
        if use_tools:
            kwargs["tools"] = TOOL_SCHEMA
            kwargs["tool_choice"] = "auto"
        
        response = oai.chat.completions.create(**kwargs)
        openai_breaker.record_success()
        return response
        
    except (RateLimitError, APIConnectionError) as e:
        openai_breaker.record_failure()
        raise  # Will be retried
    except OpenAIError as e:
        openai_breaker.record_failure()
        raise APIError(
            status_code=502,
            error_code="openai_error",
            message="Failed to get response from AI",
            detail=str(e)
        )

async def run_with_tools(messages: List[dict], user_id: str = "anonymous") -> dict:
    """Run chat completion with tool support, retry logic, and safety checks."""
    
    # 1. Run safety checks if enabled
    if ENABLE_GUARDRAILS:
        is_safe, block_reason, messages = full_safety_check(messages, user_id)
        if not is_safe:
            logger.warning(f"Request blocked: {block_reason}", extra={"user_id": user_id})
            return {
                "role": "assistant",
                "content": "I'm sorry, but I can't process that request. Please rephrase your question."
            }
    else:
        # At minimum, sanitize inputs
        messages = sanitize_messages(messages)
    
    # 2. Add system prompt and trim to fit context window
    base_msgs = [{"role": "system", "content": SYSTEM_PROMPT}] + messages
    base_msgs = trim_conversation_history(
        base_msgs,
        model=MODEL,
        max_tokens=MAX_CONTEXT_TOKENS,
    )
    
    # Log token usage
    token_count = count_messages_tokens(base_msgs)
    logger.info(f"Request context: {token_count} tokens, {len(base_msgs)} messages")
    
    try:
        # 3. Make API call with retry
        first_resp = await call_openai_with_retry(base_msgs, use_tools=True)
        
        choice = first_resp.choices[0]
        msg = choice.message
        
        # 4. Handle tool calls if needed
        if choice.finish_reason == "tool_calls" and msg.tool_calls:
            logger.info(f"Executing {len(msg.tool_calls)} tool call(s)")
            msgs_with_tools = await _apply_tool_calls(base_msgs, msg)
            
            # Second call (no tools, just get response)
            second_resp = await call_openai_with_retry(msgs_with_tools, use_tools=False)
            return second_resp.choices[0].message.model_dump()
        
        return msg.model_dump()
        
    except RetryExhausted as e:
        logger.error(f"All retries exhausted: {e.last_exception}")
        raise APIError(
            status_code=503,
            error_code="service_unavailable",
            message="AI service is currently overloaded. Please try again in a moment.",
            detail=str(e.last_exception)
        )

# =====================================================
# REQUEST / RESPONSE MODELS
# =====================================================

from typing import Literal

Role = Literal["system", "user", "assistant", "tool"]

class Message(BaseModel):
    role: Role
    content: Optional[str] = None
    name: Optional[str] = None
    tool_call_id: Optional[str] = None
    
    @field_validator('content')
    @classmethod
    def content_not_empty_for_user(cls, v, info):
        if info.data.get('role') == 'user' and (v is None or v.strip() == ''):
            raise ValueError('User message content cannot be empty')
        return v

class ChatRequest(BaseModel):
    messages: List[Message]
    
    @field_validator('messages')
    @classmethod
    def messages_not_empty(cls, v):
        if not v:
            raise ValueError('Messages list cannot be empty')
        return v

class ChatResponse(BaseModel):
    message: Dict[str, Any]

class TTSRequest(BaseModel):
    text: str
    
    @field_validator('text')
    @classmethod
    def text_not_empty(cls, v):
        if not v or not v.strip():
            raise ValueError('Text cannot be empty')
        if len(v) > 5000:
            raise ValueError('Text too long (max 5000 characters)')
        return v.strip()

# =====================================================
# FASTAPI APP
# =====================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler."""
    logger.info("üöÄ Mogul AI Agent API starting...")
    logger.info(f"Environment: {ENVIRONMENT}")
    yield
    logger.info("üëã Mogul AI Agent API shutting down...")

app = FastAPI(
    title="Mogul AI Agent API",
    description="AI-powered customer service assistant for Mogul Design Agency",
    version="2.1.0",  # Updated version for Phase 2
    lifespan=lifespan,
    docs_url="/docs" if DEBUG else None,
    redoc_url="/redoc" if DEBUG else None,
)

# =====================================================
# MIDDLEWARE
# =====================================================

from middleware import (
    RequestTracingMiddleware,
    RateLimitMiddleware,
    AuthMiddleware,
    SecurityHeadersMiddleware,
)

app.add_middleware(SecurityHeadersMiddleware)

origins = [
    o.strip() 
    for o in os.environ.get("CORS_ORIGINS", "http://localhost:3000").split(",")
    if o.strip()
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["X-Request-ID", "X-RateLimit-Limit", "X-RateLimit-Remaining"],
)

app.add_middleware(AuthMiddleware)
app.add_middleware(RateLimitMiddleware)
app.add_middleware(RequestTracingMiddleware)

# Static files
static_dir = os.path.join(os.path.dirname(__file__), "static")
if os.path.exists(static_dir):
    app.mount("/ui", StaticFiles(directory=static_dir, html=True), name="static")

# =====================================================
# EXCEPTION HANDLERS
# =====================================================

@app.exception_handler(APIError)
async def api_error_handler(request: Request, exc: APIError):
    request_id = getattr(request.state, 'request_id', None)
    return error_response(
        exc.status_code, 
        exc.error_code, 
        exc.message, 
        exc.detail,
        request_id
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    request_id = getattr(request.state, 'request_id', None)
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return error_response(
        status_code=500,
        error_code="internal_error",
        message="An unexpected error occurred",
        detail=str(exc) if DEBUG else None,
        request_id=request_id
    )

# =====================================================
# DEPENDENCIES
# =====================================================

def get_request_id(request: Request) -> Optional[str]:
    """Dependency to get current request ID."""
    return getattr(request.state, 'request_id', None)

def get_user_id(request: Request) -> str:
    """Dependency to get current user ID."""
    return getattr(request.state, 'user_id', None) or "anonymous"

# =====================================================
# ROUTES
# =====================================================

@app.get("/")
async def root():
    return RedirectResponse(url="/ui/")

@app.get("/favicon.ico")
async def favicon():
    return Response(status_code=204)

@app.get("/healthz")
async def healthz():
    """Health check endpoint."""
    return {
        "ok": True,
        "environment": ENVIRONMENT,
        "openai": bool(OPENAI_API_KEY),
        "openai_circuit": openai_breaker.state,
        "firestore": db is not None,
        "elevenlabs": _eleven_client is not None,
        "elevenlabs_circuit": elevenlabs_breaker.state if _eleven_client else "disabled",
        "guardrails": ENABLE_GUARDRAILS,
        "model": MODEL,
    }

@app.get("/config")
def get_config():
    """Get frontend configuration."""
    return {
        "calLink": os.getenv("CALCOM_EVENT_LINK", "").strip(),
        "brandColor": os.getenv("CALCOM_BRAND_COLOR", "#111827").strip(),
    }

# =====================================================
# CHAT ENDPOINT
# =====================================================

@app.post("/v1/chat", response_model=ChatResponse)
async def chat(
    req: ChatRequest,
    request_id: str = Depends(get_request_id),
    user_id: str = Depends(get_user_id),
):
    """Main chat endpoint with AI assistant."""
    try:
        incoming = [m.model_dump(exclude_none=True) for m in req.messages]
        logger.info(f"Chat request: {len(incoming)} message(s)", extra={"user_id": user_id})
        
        message = await run_with_tools(incoming, user_id=user_id)
        save_chat_to_firestore(incoming, message, request_id)
        
        return {"message": message}
        
    except APIError:
        raise
    except Exception as e:
        logger.error(f"Chat error: {e}", exc_info=True)
        raise APIError(
            status_code=500,
            error_code="chat_error",
            message="Failed to process your message. Please try again.",
            detail=str(e)
        )

# =====================================================
# SPEECH-TO-TEXT ENDPOINT
# =====================================================

@app.post("/v1/stt")
async def speech_to_text(
    audio: UploadFile = File(...),
    request_id: str = Depends(get_request_id)
):
    """Convert audio to text using Google Speech-to-Text."""
    try:
        content = await audio.read()
        
        if len(content) < 1000:
            logger.info("STT: Audio too short")
            return {"text": "", "error": "audio_too_short"}
        
        if len(content) > 10 * 1024 * 1024:
            raise HTTPException(status_code=413, detail="Audio file too large (max 10MB)")
        
        from google.cloud import speech_v1p1beta1 as speech
        
        client = get_speech_client()
        audio_cfg = speech.RecognitionAudio(content=content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
            language_code="en-US",
            enable_automatic_punctuation=True,
            model="default",
        )
        
        resp = client.recognize(config=config, audio=audio_cfg)
        
        if not resp.results:
            logger.info("STT: No speech detected")
            return {"text": ""}
        
        transcript = resp.results[0].alternatives[0].transcript
        confidence = resp.results[0].alternatives[0].confidence
        
        logger.info(f"üéôÔ∏è Transcribed ({confidence:.0%}): {transcript[:50]}...")
        return {"text": transcript, "confidence": confidence}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"STT error: {e}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={"text": "", "error": "transcription_failed", "detail": str(e)}
        )

# =====================================================
# TEXT-TO-SPEECH ENDPOINT WITH RETRY
# =====================================================

@app.post("/v1/tts")
async def text_to_speech(payload: TTSRequest):
    """Convert text to speech audio with fallback."""
    text = payload.text
    
    # Try ElevenLabs first (with circuit breaker)
    if _eleven_client and elevenlabs_breaker.allow_request():
        try:
            audio_stream = _eleven_client.text_to_speech.convert(
                voice_id=ELEVENLABS_VOICE_ID,
                model_id="eleven_multilingual_v2",
                text=text,
                output_format="mp3_44100_128",
            )
            
            audio_bytes = b"".join(chunk for chunk in audio_stream)
            elevenlabs_breaker.record_success()
            logger.info(f"üîä ElevenLabs TTS: {len(audio_bytes)} bytes")
            
            return StreamingResponse(
                io.BytesIO(audio_bytes),
                media_type="audio/mpeg",
                headers={"Content-Length": str(len(audio_bytes))}
            )
            
        except Exception as e:
            elevenlabs_breaker.record_failure()
            logger.warning(f"ElevenLabs failed, using fallback: {e}")
    
    # Google TTS fallback
    try:
        from google.cloud import texttospeech
        
        tts_client = get_tts_client()
        synthesis_input = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(
            language_code="en-US",
            ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL,
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3
        )
        
        tts_resp = tts_client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )
        
        audio_bytes = tts_resp.audio_content
        logger.info(f"üîä Google TTS: {len(audio_bytes)} bytes")
        
        return StreamingResponse(
            io.BytesIO(audio_bytes),
            media_type="audio/mpeg",
            headers={"Content-Length": str(len(audio_bytes))}
        )
        
    except Exception as e:
        logger.error(f"TTS error: {e}", exc_info=True)
        raise APIError(
            status_code=500,
            error_code="tts_error",
            message="Failed to generate speech",
            detail=str(e)
        )

# =====================================================
# TWILIO SMS WEBHOOK
# =====================================================

@app.post("/twilio/sms")
async def sms_webhook(request: Request):
    """Handle incoming SMS via Twilio webhook."""
    try:
        form = await request.form()
        body = form.get("Body", "")
        from_number = form.get("From", "unknown")
        
        logger.info(f"üì± SMS from {from_number}: {body[:50]}...")
        
        return HTMLResponse(
            content=f"""<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Message>Thanks for your message! Our AI assistant received: {body}</Message>
</Response>""",
            media_type="application/xml",
        )
    except Exception as e:
        logger.error(f"SMS webhook error: {e}")
        return HTMLResponse(
            content="""<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Message>Sorry, we couldn't process your message.</Message>
</Response>""",
            media_type="application/xml",
        )

# =====================================================
# LIVEKIT TOKEN (Placeholder)
# =====================================================

@app.get("/v1/livekit-token")
async def get_livekit_token(identity: str = "browser-user"):
    """Generate LiveKit token (future feature)."""
    return {"token": "livekit-token-placeholder", "identity": identity}